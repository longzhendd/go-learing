## requests
### 通用框架
```python
import requests
def getHTMLText(url):
    try:
        r=requests.request("GET",url,timeout=30)
        r.raise_for_status()
        r.encoding=r.apparent_encoding
        return r.text
    except:
        return "error"
if __name__ == '__main__':
    url="http://www.baidu.com"
    print(getHTMLText(url))
    
```
### 请求方式及传参
`get/post/delete/put/patch/head`
* params 参数添加到url中，字典或字节序列
* data 参数放在body中，字典、字节序列、文件为对象
* json JSON格式的数据，放在body中
* headers 字典类型，http请求头
* cookies 字典或cookiejar类型，请求的cookies
* auth 元组，支持http认证
* file 字典类型传文件
```
fs={'file':open('data.xls','rb')}
r= requests.request('post',url,files=fs)
```
* timeout 超时时间，单位为秒
* proxies 字典类型，设定代理服务器
```
pxs={'http':'http://user:pass@10.10.10.1:1024','https':'http://10.10.10.1:3214'}
```

### 网络爬虫限制
* 发布robots.txt
* 来源审查：判断user-agent（只响应浏览器或友好爬虫的访问）

### robots协议
解释：robots exclusion standard，网络爬虫排除标准
作用：告知网站是否可爬取
形式：根目录下robots.txt文件

### 实例:图片爬取
`图片爬取`

```
import requests
import os
import sys
url="https://seopic.699pic.com/photo/50046/5562.jpg_wh1200.jpg"
root=os.path.dirname(__file__)
path=root+ '/' +url.split('/')[-1]
print(path)
try:
    if not os.path.exists(root):
        os.makedirs(root)
    if not os.path.exists(path):
        r=requests.get(url)
        with open(path,'wb') as f:
            f.write(r.content)  #content：返回的是bytes字节码
            f.close()
            print('success')
    else:
        print('existed')
except:
    print('error')
```

### beautiful soup
说明：解析HTML网页
* BeautifulSoup解析器
|解析器|使用|条件|
|:--:|:--:|:--:|
|bs4的HTML解析|BeautifulSoup(mk,'html.parser')|安装bs4|
|lxml的HTML解析|BeautifulSoup(mk,'lxml')|pip install lxml|
|lxml的XML解析|BeautifulSoup(mk,'xml')|pip install lxml|
|html5lib的解析|BeautifulSoup(mk,'html5lib')|pip install html5lib|

* Beautifulsoup基本元素
|基本元素|说明|
|--|--|
|tag|标签|
|name|标签名|
|attributes|标签属性|
|navigablestring|标签内非属性字符串|
|comment|标签内字符串注释部分|

```python
import requests
from bs4 import BeautifulSoup
r=requests.get("http://www.baidu.com")
r.encoding=r.apparent_encoding
demo=r.text
soup=BeautifulSoup(demo,'html.parser')
# print(soup.prettify())
tag=soup.a
print(tag)
print(tag.name)
print(tag.parent.name)
print(tag.attrs)
print(tag.string)
```

### 标签树遍历
* 上行遍历
```
# 上行遍历
for parent in soup.a.parents:
    if parent is None:
        print(parent)
    else:
        print(parent.name)
```
* 下行遍历
```
# 下行遍历
for child in soup.body.children:
    print(child)
for child in soup.body.descendants:
    print(child)
```
* 平行遍历
```python
for sibling in soup.a.next_sibling:
	print(sibling)	#遍历后续
for sibling in soup.a.previous_sibling:
	print(sibling)	#遍历前续
```

### bs4中的prettify()方法
```
>>> print(soup.a.prettify())
<a class="mnav" href="http://news.baidu.com" name="tj_trnews">
 新闻
</a>
```

### 信息标记与提取
